{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV,RandomizedSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dataset\n",
    "# df = pd.read_csv('emails.csv')\n",
    "# df.head()\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Drop 'Email No.' column as it's not a feature for prediction\n",
    "# df = df.drop(columns=['Email No.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split features and target variable\n",
    "# X = df.drop(columns=['Prediction'])\n",
    "# y = df['Prediction']\n",
    "# # Scale numerical features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the models and their hyperparameter grids\n",
    "# model_params = {'Random Forest': {\n",
    "#         'model': RandomForestClassifier(),\n",
    "#         'params': {'n_estimators': [50, 100, 200],'max_depth': [None, 10, 20, 30],\n",
    "#                    'min_samples_split': [2, 5, 10] }\n",
    "#     }\n",
    "\n",
    "#     # 'Logistic Regression': {\n",
    "#     #     'model': LogisticRegression(max_iter=10000),\n",
    "#     #     'params': {\n",
    "#     #         'C': [0.1, 1, 10],\n",
    "#     #         'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "#     #     }\n",
    "#     # },\n",
    "#     # 'Decision Tree': {\n",
    "#     #     'model': DecisionTreeClassifier(),\n",
    "#     #     'params': {\n",
    "#     #         'max_depth': [None, 10, 20, 30],\n",
    "#     #         'min_samples_split': [2, 5, 10],\n",
    "#     #         'min_samples_leaf': [1, 2, 4]\n",
    "#     #     }\n",
    "#     # },\n",
    "#     # 'Support Vector Machine': {\n",
    "#     #     'model': SVC(),\n",
    "#     #     'params': {\n",
    "#     #         'C': [0.1, 1, 10],\n",
    "#     #         'kernel': ['linear', 'rbf', 'poly'],\n",
    "#     #         'gamma': ['scale', 'auto']\n",
    "#     #     }\n",
    "#     # },\n",
    "    \n",
    "#     # 'Gradient Boosting': {\n",
    "#     #     'model': GradientBoostingClassifier(),\n",
    "#     #     'params': {\n",
    "#     #         'n_estimators': [50, 100, 200],\n",
    "#     #         'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     #         'max_depth': [3, 5, 7]\n",
    "#     #     }\n",
    "#     # }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to evaluate the model\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "#     recall = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a dictionary to store the best models and their performance metrics\n",
    "# best_models = {}\n",
    "# best_model_performance = {}\n",
    "\n",
    "# # Random Search for comparison\n",
    "# for model_name, mp in model_params.items():\n",
    "#     random_search = RandomizedSearchCV(mp['model'], mp['params'], n_iter=10, cv=5, n_jobs=2,scoring='accuracy', random_state=42)\n",
    "#     random_search.fit(X_train, y_train)\n",
    "#     best_random_model = random_search.best_estimator_\n",
    "#     accuracy, precision, recall, f1 = evaluate_model(best_random_model, X_test, y_test)\n",
    "\n",
    "#     # Store the best model and its performance\n",
    "#     best_models[model_name] = best_random_model\n",
    "#     best_model_performance[model_name] = {\n",
    "#         'accuracy': accuracy,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall,\n",
    "#         'f1_score': f1\n",
    "#     }\n",
    "#     print(f'{model_name} Performance after Random Search:')\n",
    "#     print(f'Best Parameters: {best_random_model.get_params()}')\n",
    "#     print(f'Accuracy: {accuracy:.2f}')\n",
    "#     print(f'Precision: {precision:.2f}')\n",
    "#     print(f'Recall: {recall:.2f}')\n",
    "#     print(f'F1-score: {f1:.2f}')\n",
    "#     # Cross-validation\n",
    "#     scores = cross_val_score(best_random_model, X, y, cv=5, scoring='accuracy')\n",
    "#     print(f'Cross-Validation Accuracy: {scores.mean():.2f}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify the best model based on accuracy (or another metric of your choice)\n",
    "# best_model_name = max(best_model_performance, key=lambda k: best_model_performance[k]['accuracy'])\n",
    "# best_model = best_models[best_model_name]\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions with the best model\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # Displaying some example predictions\n",
    "# predictions = pd.DataFrame({\n",
    "#     'Email': X_test.index,\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred\n",
    "# })\n",
    "\n",
    "# print(f'\\nBest Model: {best_model_name}')\n",
    "# print(predictions.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the Random Forest model and its hyperparameter grid\n",
    "# random_forest_params = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# # Hyperparameter tuning using GridSearchCV\n",
    "# grid_search = GridSearchCV(RandomForestClassifier(), random_forest_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_grid_model = grid_search.best_estimator_\n",
    "\n",
    "# # Evaluate the tuned Random Forest model from GridSearchCV\n",
    "# accuracy, precision, recall, f1 = evaluate_model(best_grid_model, X_test, y_test)\n",
    "# print(f'Random Forest Performance after Grid Search:')\n",
    "# print(f'Best Parameters: {best_grid_model.get_params()}')\n",
    "# print(f'Accuracy: {accuracy:.2f}')\n",
    "# print(f'Precision: {precision:.2f}')\n",
    "# print(f'Recall: {recall:.2f}')\n",
    "# print(f'F1-score: {f1:.2f}')\n",
    "\n",
    "# # Cross-validation\n",
    "# scores = cross_val_score(best_grid_model, X, y, cv=5, scoring='accuracy')\n",
    "# print(f'Cross-Validation Accuracy: {scores.mean():.2f}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter tuning using RandomizedSearchCV\n",
    "# random_search = RandomizedSearchCV(RandomForestClassifier(), random_forest_params, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "# random_search.fit(X_train, y_train)\n",
    "# best_random_model = random_search.best_estimator_\n",
    "\n",
    "# # Evaluate the tuned Random Forest model from RandomizedSearchCV\n",
    "# accuracy, precision, recall, f1 = evaluate_model(best_random_model, X_test, y_test)\n",
    "# print(f'Random Forest Performance after Random Search:')\n",
    "# print(f'Best Parameters: {best_random_model.get_params()}')\n",
    "# print(f'Accuracy: {accuracy:.2f}')\n",
    "# print(f'Precision: {precision:.2f}')\n",
    "# print(f'Recall: {recall:.2f}')\n",
    "# print(f'F1-score: {f1:.2f}')\n",
    "\n",
    "# # Cross-validation\n",
    "# scores = cross_val_score(best_random_model, X, y, cv=5, scoring='accuracy')\n",
    "# print(f'Cross-Validation Accuracy: {scores.mean():.2f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the best model from Grid Search for predictions\n",
    "# y_pred = best_grid_model.predict(X_test)\n",
    "\n",
    "# # Displaying some example predictions\n",
    "# predictions = pd.DataFrame({\n",
    "#     'Email': X_test.index,  # Assuming the index represents the email ID or identifier\n",
    "#     'Actual': y_test,\n",
    "#     'Predicted': y_pred\n",
    "# })\n",
    "\n",
    "# print(predictions.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>Email 5168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>Email 5169</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>Email 5170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>Email 5171</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>Email 5172</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  \\\n",
       "5167  Email 5168    2   2    2    3    0   0   32    0    0  ...         0   \n",
       "5168  Email 5169   35  27   11    2    6   5  151    4    3  ...         0   \n",
       "5169  Email 5170    0   0    1    1    0   0   11    0    0  ...         0   \n",
       "5170  Email 5171    2   7    1    0    2   1   28    2    0  ...         0   \n",
       "5171  Email 5172   22  24    5    1    6   5  148    8    2  ...         0   \n",
       "\n",
       "      jay  valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
       "5167    0       0    0               0         0         0   0    0   \n",
       "5168    0       0    0               0         0         0   1    0   \n",
       "5169    0       0    0               0         0         0   0    0   \n",
       "5170    0       0    0               0         0         0   1    0   \n",
       "5171    0       0    0               0         0         0   0    0   \n",
       "\n",
       "      Prediction  \n",
       "5167           0  \n",
       "5168           0  \n",
       "5169           1  \n",
       "5170           1  \n",
       "5171           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('emails.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email No.     0\n",
       "the           0\n",
       "to            0\n",
       "ect           0\n",
       "and           0\n",
       "             ..\n",
       "military      0\n",
       "allowing      0\n",
       "ff            0\n",
       "dry           0\n",
       "Prediction    0\n",
       "Length: 3002, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Email No.' column as it's not a feature for prediction\n",
    "df = df.drop(columns=['Email No.'])\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['Prediction'])\n",
    "y = df['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest model and its hyperparameter grid\n",
    "random_forest_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance after Grid Search:\n",
      "Best Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 30, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Accuracy: 0.98\n",
      "Precision: 0.96\n",
      "Recall: 0.97\n",
      "F1-score: 0.96\n",
      "Cross-Validation Accuracy: 0.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), random_forest_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_grid_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned Random Forest model from GridSearchCV\n",
    "accuracy, precision, recall, f1 = evaluate_model(best_grid_model, X_test, y_test)\n",
    "print(f'Random Forest Performance after Grid Search:')\n",
    "print(f'Best Parameters: {best_grid_model.get_params()}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-score: {f1:.2f}')\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(best_grid_model, X, y, cv=5, scoring='accuracy')\n",
    "print(f'Cross-Validation Accuracy: {scores.mean():.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance after Random Search:\n",
      "Best Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 30, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Accuracy: 0.98\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n",
      "F1-score: 0.96\n",
      "Cross-Validation Accuracy: 0.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), random_forest_params, n_iter=10, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_random_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned Random Forest model from RandomizedSearchCV\n",
    "accuracy, precision, recall, f1 = evaluate_model(best_random_model, X_test, y_test)\n",
    "print(f'Random Forest Performance after Random Search:')\n",
    "print(f'Best Parameters: {best_random_model.get_params()}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-score: {f1:.2f}')\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(best_random_model, X, y, cv=5, scoring='accuracy')\n",
    "print(f'Cross-Validation Accuracy: {scores.mean():.2f}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Email  Actual  Predicted\n",
      "1566   1566       0          0\n",
      "1988   1988       0          0\n",
      "1235   1235       1          1\n",
      "3276   3276       0          0\n",
      "3438   3438       0          0\n",
      "1471   1471       0          0\n",
      "1129   1129       1          1\n",
      "3750   3750       0          0\n",
      "3049   3049       0          0\n",
      "530     530       0          0\n"
     ]
    }
   ],
   "source": [
    "# Using the best model from Grid Search for predictions\n",
    "y_pred = best_grid_model.predict(X_test)\n",
    "\n",
    "# Displaying some example predictions\n",
    "predictions = pd.DataFrame({\n",
    "    'Email': X_test.index,  # Assuming the index represents the email ID or identifier\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "print(predictions.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
